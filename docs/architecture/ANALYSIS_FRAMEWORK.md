# ğŸ“Š Post-Campaign Analysis Framework

## ğŸ¯ **Scenario-Based Analysis Selection Guide**

Understanding **which analysis to apply in which scenario** is critical for actionable insights.

---

## 1ï¸âƒ£ **Performance Analysis**

### **When to Use**:
- âœ… Campaign just ended - need overall health check
- âœ… Mid-campaign optimization review
- âœ… Stakeholder reporting (executives, clients)
- âœ… Budget allocation decisions

### **Key Metrics**:

#### **Reach & Frequency**
```sql
-- Unique reach and average frequency
SELECT 
    Campaign_Name,
    SUM(Reach) as total_reach,
    (SUM(Impressions) * 1.0 / SUM(Reach)) as avg_frequency
FROM campaigns
GROUP BY Campaign_Name
```

**Scenarios**:
- ğŸ“Œ **High frequency, low reach**: Oversaturation - expand targeting
- ğŸ“Œ **Low frequency, high reach**: Awareness campaign - good for brand building
- ğŸ“Œ **Frequency > 5**: Risk of ad fatigue - creative refresh needed

#### **Engagement Metrics**
```sql
-- CTR, video completion, engagement rate
SELECT 
    Placement,
    (SUM(Clicks) * 100.0 / SUM(Impressions)) as ctr,
    (SUM(Video_Views) * 100.0 / SUM(Impressions)) as video_view_rate,
    (SUM(Engagement) * 100.0 / SUM(Impressions)) as engagement_rate
FROM campaigns
GROUP BY Placement
```

**Scenarios**:
- ğŸ“Œ **Low CTR (<1%)**: Creative or targeting issue
- ğŸ“Œ **High views, low completion**: Video too long or not engaging
- ğŸ“Œ **High engagement, low conversion**: Awareness working, funnel broken

#### **Conversion Tracking**
```sql
-- Conversion funnel analysis
SELECT 
    Campaign_Name,
    SUM(Impressions) as impressions,
    SUM(Clicks) as clicks,
    SUM(Conversions) as conversions,
    (SUM(Clicks) * 100.0 / SUM(Impressions)) as ctr,
    (SUM(Conversions) * 100.0 / SUM(Clicks)) as conv_rate
FROM campaigns
GROUP BY Campaign_Name
```

**Scenarios**:
- ğŸ“Œ **High CTR, low conv rate**: Landing page issue
- ğŸ“Œ **Low CTR, high conv rate**: Good targeting, poor creative
- ğŸ“Œ **Both low**: Fundamental campaign issue

#### **Cost Efficiency**
```sql
-- Cost metrics comparison
SELECT 
    Campaign_Name,
    (SUM(Spend) / SUM(Clicks)) as cpc,
    (SUM(Spend) / SUM(Impressions) * 1000) as cpm,
    (SUM(Spend) / SUM(Conversions)) as cpa,
    (SUM(Revenue) / SUM(Spend)) as roas
FROM campaigns
GROUP BY Campaign_Name
```

**Scenarios**:
- ğŸ“Œ **CPA > target**: Need optimization or pause
- ğŸ“Œ **ROAS < 1**: Losing money - immediate action
- ğŸ“Œ **CPM increasing**: Auction pressure or ad fatigue

---

## 2ï¸âƒ£ **Statistical Testing**

### **When to Use**:
- âœ… A/B test results need validation
- âœ… Proving campaign incrementality
- âœ… Budget justification to CFO
- âœ… Understanding true impact vs correlation

### **A/B Testing Results**

**Scenario**: Testing 2 ad creatives
```sql
-- Compare Creative A vs Creative B
SELECT 
    Creative_Name,
    SUM(Impressions) as impressions,
    SUM(Clicks) as clicks,
    (SUM(Clicks) * 100.0 / SUM(Impressions)) as ctr,
    SUM(Conversions) as conversions,
    (SUM(Conversions) * 100.0 / SUM(Clicks)) as conv_rate
FROM campaigns
WHERE Creative_Name IN ('Creative_A', 'Creative_B')
GROUP BY Creative_Name
```

**Statistical Tests Needed**:
- **Chi-square test**: Is CTR difference significant?
- **T-test**: Is conversion rate difference significant?
- **Sample size**: Do we have enough data?

**Decision Framework**:
- ğŸ“Œ **p-value < 0.05**: Statistically significant - scale winner
- ğŸ“Œ **p-value > 0.05**: Not significant - need more data
- ğŸ“Œ **Small sample**: Don't make decisions yet

### **Lift Studies**

**Scenario**: Proving campaign drove incremental sales
```sql
-- Compare exposed vs control group
SELECT 
    'Exposed' as group_type,
    COUNT(DISTINCT user_id) as users,
    SUM(conversions) as conversions,
    (SUM(conversions) * 1.0 / COUNT(DISTINCT user_id)) as conv_per_user
FROM exposed_users
UNION ALL
SELECT 
    'Control' as group_type,
    COUNT(DISTINCT user_id) as users,
    SUM(conversions) as conversions,
    (SUM(conversions) * 1.0 / COUNT(DISTINCT user_id)) as conv_per_user
FROM control_users
```

**Lift Calculation**:
```
Lift = (Exposed Conv Rate - Control Conv Rate) / Control Conv Rate * 100
```

**Scenarios**:
- ğŸ“Œ **Positive lift**: Campaign is incremental - continue
- ğŸ“Œ **No lift**: Campaign not driving incremental value
- ğŸ“Œ **Negative lift**: Something wrong - investigate

### **Attribution Modeling**

**Scenario**: Understanding channel contribution
```sql
-- Multi-touch attribution
SELECT 
    Channel,
    SUM(first_touch_conversions) as first_touch,
    SUM(last_touch_conversions) as last_touch,
    SUM(linear_attribution_conversions) as linear,
    SUM(time_decay_conversions) as time_decay
FROM attribution_data
GROUP BY Channel
```

**When to Use**:
- ğŸ“Œ **First-touch**: Understanding awareness drivers
- ğŸ“Œ **Last-touch**: Understanding conversion drivers
- ğŸ“Œ **Linear**: Equal credit to all touchpoints
- ğŸ“Œ **Time-decay**: Recent touchpoints get more credit

---

## 3ï¸âƒ£ **Audience Analysis**

### **When to Use**:
- âœ… Planning next campaign targeting
- âœ… Understanding who responds best
- âœ… Personalizing creative strategy
- âœ… Budget allocation by segment

### **Demographic Performance**

**Scenario**: Which age/gender segments perform best?
```sql
-- Performance by demographics
SELECT 
    Age,
    Gender,
    SUM(Impressions) as impressions,
    (SUM(Clicks) * 100.0 / SUM(Impressions)) as ctr,
    (SUM(Conversions) * 100.0 / SUM(Clicks)) as conv_rate,
    (SUM(Revenue) / SUM(Spend)) as roas
FROM campaigns
GROUP BY Age, Gender
ORDER BY roas DESC
```

**Decision Framework**:
- ğŸ“Œ **High ROAS segment**: Increase budget allocation
- ğŸ“Œ **Low ROAS segment**: Reduce or pause
- ğŸ“Œ **High CTR, low conv**: Different creative needed

### **Geographic Analysis**

**Scenario**: Regional performance variations
```sql
-- Performance by location
SELECT 
    Location,
    SUM(Spend) as spend,
    SUM(Revenue) as revenue,
    (SUM(Revenue) / SUM(Spend)) as roas,
    (SUM(Spend) / SUM(Conversions)) as cpa
FROM campaigns
GROUP BY Location
ORDER BY roas DESC
```

**Scenarios**:
- ğŸ“Œ **High-performing regions**: Increase geo-targeting
- ğŸ“Œ **Low-performing regions**: Investigate or exit
- ğŸ“Œ **Seasonal patterns**: Adjust by region

### **Device & Platform Breakdown**

**Scenario**: Cross-device behavior
```sql
-- Device performance
SELECT 
    Device,
    SUM(Impressions) as impressions,
    (SUM(Clicks) * 100.0 / SUM(Impressions)) as ctr,
    (SUM(Spend) / SUM(Clicks)) as cpc,
    (SUM(Revenue) / SUM(Spend)) as roas
FROM campaigns
GROUP BY Device
```

**Decision Framework**:
- ğŸ“Œ **Mobile high CTR, low conv**: Mobile landing page issue
- ğŸ“Œ **Desktop high ROAS**: Allocate more desktop budget
- ğŸ“Œ **CTV high engagement**: Consider video-first strategy

---

## 4ï¸âƒ£ **Temporal Analysis**

### **When to Use**:
- âœ… Optimizing ad scheduling
- âœ… Understanding user behavior patterns
- âœ… Budget pacing optimization
- âœ… Identifying best times to advertise

### **Dayparting**

**Scenario**: When do ads perform best?
```sql
-- Performance by hour of day
SELECT 
    EXTRACT(HOUR FROM timestamp) as hour_of_day,
    EXTRACT(DOW FROM timestamp) as day_of_week,
    SUM(Impressions) as impressions,
    (SUM(Clicks) * 100.0 / SUM(Impressions)) as ctr,
    (SUM(Conversions) * 100.0 / SUM(Clicks)) as conv_rate
FROM campaigns
GROUP BY hour_of_day, day_of_week
ORDER BY conv_rate DESC
```

**Decision Framework**:
- ğŸ“Œ **High conv rate hours**: Increase bids during these times
- ğŸ“Œ **Low conv rate hours**: Reduce bids or pause
- ğŸ“Œ **Weekend vs weekday**: Adjust strategy accordingly

### **Trend Analysis**

**Scenario**: Performance trajectory over time
```sql
-- Daily performance trend
SELECT 
    Date,
    SUM(Spend) as daily_spend,
    SUM(Revenue) as daily_revenue,
    (SUM(Revenue) / SUM(Spend)) as daily_roas,
    AVG((SUM(Revenue) / SUM(Spend))) OVER (
        ORDER BY Date 
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    ) as rolling_7day_roas
FROM campaigns
GROUP BY Date
ORDER BY Date
```

**Scenarios**:
- ğŸ“Œ **Declining ROAS**: Ad fatigue - refresh creative
- ğŸ“Œ **Improving ROAS**: Learning phase working - scale up
- ğŸ“Œ **Volatile ROAS**: Inconsistent delivery - investigate

### **Pacing Analysis**

**Scenario**: Budget utilization tracking
```sql
-- Budget pacing
SELECT 
    Campaign_Name,
    SUM(Spend) as spent_to_date,
    MAX(budget) as total_budget,
    (SUM(Spend) * 100.0 / MAX(budget)) as pct_spent,
    DATEDIFF(MAX(end_date), CURRENT_DATE) as days_remaining
FROM campaigns
GROUP BY Campaign_Name
```

**Decision Framework**:
- ğŸ“Œ **Underpacing (<80% at 80% time)**: Increase bids/budget
- ğŸ“Œ **Overpacing (>80% at 50% time)**: Reduce bids/budget
- ğŸ“Œ **On pace**: Continue monitoring

---

## 5ï¸âƒ£ **Comparative Analysis**

### **When to Use**:
- âœ… Benchmarking against standards
- âœ… Channel mix optimization
- âœ… Creative testing and optimization
- âœ… Competitive analysis

### **Benchmark Comparison**

**Scenario**: How do we compare to industry standards?
```sql
-- Campaign vs benchmark
SELECT 
    Campaign_Name,
    (SUM(Clicks) * 100.0 / SUM(Impressions)) as actual_ctr,
    2.5 as industry_benchmark_ctr,
    (((SUM(Clicks) * 100.0 / SUM(Impressions)) - 2.5) / 2.5 * 100) as pct_vs_benchmark
FROM campaigns
GROUP BY Campaign_Name
```

**Benchmarks by Industry**:
- ğŸ“Œ **E-commerce**: CTR 1.5-2.5%, Conv Rate 2-3%
- ğŸ“Œ **B2B**: CTR 2-3%, Conv Rate 5-10%
- ğŸ“Œ **Finance**: CTR 0.5-1%, Conv Rate 5-10%

### **Channel Comparison**

**Scenario**: Which channels drive best results?
```sql
-- Cross-channel performance
SELECT 
    Channel,
    SUM(Spend) as spend,
    SUM(Revenue) as revenue,
    (SUM(Revenue) / SUM(Spend)) as roas,
    (SUM(Spend) / SUM(Conversions)) as cpa,
    SUM(Conversions) as conversions
FROM campaigns
GROUP BY Channel
ORDER BY roas DESC
```

**Decision Framework**:
- ğŸ“Œ **High ROAS channel**: Increase budget allocation
- ğŸ“Œ **Low ROAS channel**: Optimize or reduce
- ğŸ“Œ **High volume, low ROAS**: Good for awareness, not conversion

### **Creative Performance**

**Scenario**: Which assets drive best results?
```sql
-- Creative performance comparison
SELECT 
    Creative_Name,
    Creative_Type,
    SUM(Impressions) as impressions,
    (SUM(Clicks) * 100.0 / SUM(Impressions)) as ctr,
    (SUM(Conversions) * 100.0 / SUM(Clicks)) as conv_rate,
    (SUM(Revenue) / SUM(Spend)) as roas
FROM campaigns
GROUP BY Creative_Name, Creative_Type
ORDER BY roas DESC
```

**Decision Framework**:
- ğŸ“Œ **Top 20% creatives**: Scale these
- ğŸ“Œ **Bottom 20% creatives**: Pause these
- ğŸ“Œ **Middle 60%**: Test variations

---

## 6ï¸âƒ£ **Business Impact**

### **When to Use**:
- âœ… C-suite reporting
- âœ… Budget justification
- âœ… Long-term strategy planning
- âœ… Brand health tracking

### **Brand Lift Studies**

**Scenario**: Did campaign improve brand metrics?
```sql
-- Brand metrics comparison (pre vs post campaign)
SELECT 
    metric_type,
    pre_campaign_score,
    post_campaign_score,
    (post_campaign_score - pre_campaign_score) as absolute_lift,
    ((post_campaign_score - pre_campaign_score) / pre_campaign_score * 100) as pct_lift
FROM brand_lift_study
WHERE metric_type IN ('Awareness', 'Consideration', 'Preference', 'Intent')
```

**Interpretation**:
- ğŸ“Œ **Awareness lift >5%**: Strong brand building
- ğŸ“Œ **Consideration lift >3%**: Moving down funnel
- ğŸ“Œ **Intent lift >2%**: Close to conversion

### **Sales Impact Analysis**

**Scenario**: Campaign impact on sales
```sql
-- Sales correlation with media spend
SELECT 
    DATE_TRUNC('week', date) as week,
    SUM(media_spend) as weekly_spend,
    SUM(sales) as weekly_sales,
    LAG(SUM(sales), 1) OVER (ORDER BY DATE_TRUNC('week', date)) as prev_week_sales,
    (SUM(sales) - LAG(SUM(sales), 1) OVER (ORDER BY DATE_TRUNC('week', date))) as sales_change
FROM campaign_sales_data
GROUP BY week
ORDER BY week
```

**Analysis**:
- ğŸ“Œ **Correlation coefficient >0.7**: Strong relationship
- ğŸ“Œ **Lag analysis**: How long does impact take?
- ğŸ“Œ **Diminishing returns**: When does more spend not help?

### **Customer Acquisition Analysis**

**Scenario**: Quality and cost of acquired customers
```sql
-- Customer acquisition metrics
SELECT 
    Campaign_Name,
    COUNT(DISTINCT customer_id) as new_customers,
    (SUM(Spend) / COUNT(DISTINCT customer_id)) as cac,
    AVG(customer_lifetime_value) as avg_ltv,
    (AVG(customer_lifetime_value) / (SUM(Spend) / COUNT(DISTINCT customer_id))) as ltv_cac_ratio
FROM customer_acquisition
GROUP BY Campaign_Name
```

**Decision Framework**:
- ğŸ“Œ **LTV:CAC > 3:1**: Healthy acquisition
- ğŸ“Œ **LTV:CAC < 1:1**: Losing money on customers
- ğŸ“Œ **CAC increasing**: Need optimization

---

## ğŸ¯ **Decision Matrix: Which Analysis When?**

| Scenario | Primary Analysis | Secondary Analysis | Key Metrics |
|----------|-----------------|-------------------|-------------|
| **Campaign just ended** | Performance Analysis | Comparative Analysis | ROAS, CPA, CTR |
| **Mid-campaign check** | Temporal Analysis | Performance Analysis | Pacing, Daily ROAS |
| **Budget allocation** | Audience Analysis | Channel Comparison | ROAS by segment |
| **Creative refresh** | Creative Performance | A/B Testing | CTR, Engagement |
| **Proving ROI to CFO** | Statistical Testing | Business Impact | Lift, Incrementality |
| **Planning next campaign** | Audience Analysis | Benchmark Comparison | Best segments |
| **Ad fatigue suspected** | Temporal Analysis | Engagement Metrics | Frequency, CTR trend |
| **Landing page issue** | Conversion Tracking | Device Analysis | Conv rate by device |
| **Brand campaign** | Brand Lift Studies | Reach & Frequency | Awareness lift |
| **Performance campaign** | Cost Efficiency | Conversion Tracking | CPA, ROAS |

---

## ğŸ“š **Analysis Workflow**

### **Step 1: Define Objective**
- What decision needs to be made?
- Who is the audience for this analysis?
- What's the timeline?

### **Step 2: Select Analysis Type**
- Use decision matrix above
- Consider data availability
- Align with business goals

### **Step 3: Run Analysis**
- Execute appropriate SQL queries
- Apply statistical tests if needed
- Validate data quality

### **Step 4: Interpret Results**
- Compare to benchmarks
- Identify patterns and anomalies
- Consider external factors

### **Step 5: Generate Insights**
- What's working and why?
- What's not working and why?
- What should we do differently?

### **Step 6: Make Recommendations**
- Specific, actionable recommendations
- Prioritized by impact
- Include expected outcomes

---

## ğŸ“ **Key Principles**

1. **Context Matters**: Same metric means different things in different scenarios
2. **Multiple Lenses**: Use 2-3 analysis types for complete picture
3. **Statistical Rigor**: Don't confuse correlation with causation
4. **Actionability**: Every analysis should lead to a decision
5. **Continuous Learning**: Track what works and iterate

---

**This framework ensures you apply the RIGHT analysis in the RIGHT scenario for ACTIONABLE insights.**
